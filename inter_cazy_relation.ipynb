{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\dgg32\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "error loading _jsonnet (this is expected on Windows), treating C:\\Users\\dgg32\\AppData\\Local\\Temp\\tmp_dhkurff\\config.json as plain json\n",
      "Some weights of the model checkpoint at microsoft/infoxlm-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline\n",
    "import spacy\n",
    "import sys\n",
    "import gpt3\n",
    "import cross_coref\n",
    "import entity_linkage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"pucpr/clinicalnerpt-chemical\")\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"pucpr/clinicalnerpt-chemical\")\n",
    "\n",
    "model_infer = pipeline('ner',model=model,tokenizer=tokenizer)\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CBM0',\n",
       " 'CBM1',\n",
       " 'CBM10',\n",
       " 'CBM11',\n",
       " 'CBM12',\n",
       " 'CBM13',\n",
       " 'CBM14',\n",
       " 'CBM15',\n",
       " 'CBM16',\n",
       " 'CBM17',\n",
       " 'CBM18',\n",
       " 'CBM19',\n",
       " 'CBM2',\n",
       " 'CBM20',\n",
       " 'CBM21',\n",
       " 'CBM22',\n",
       " 'CBM23',\n",
       " 'CBM24',\n",
       " 'CBM25',\n",
       " 'CBM26',\n",
       " 'CBM27',\n",
       " 'CBM28',\n",
       " 'CBM29',\n",
       " 'CBM3',\n",
       " 'CBM30',\n",
       " 'CBM32',\n",
       " 'CBM33',\n",
       " 'CBM34',\n",
       " 'CBM35',\n",
       " 'CBM36',\n",
       " 'CBM37',\n",
       " 'CBM38',\n",
       " 'CBM39',\n",
       " 'CBM4',\n",
       " 'CBM40',\n",
       " 'CBM41',\n",
       " 'CBM42',\n",
       " 'CBM43',\n",
       " 'CBM44',\n",
       " 'CBM45',\n",
       " 'CBM46',\n",
       " 'CBM47',\n",
       " 'CBM48',\n",
       " 'CBM49',\n",
       " 'CBM5',\n",
       " 'CBM50',\n",
       " 'CBM51',\n",
       " 'CBM52',\n",
       " 'CBM53',\n",
       " 'CBM54',\n",
       " 'CBM55',\n",
       " 'CBM56',\n",
       " 'CBM57',\n",
       " 'CBM58',\n",
       " 'CBM59',\n",
       " 'CBM6',\n",
       " 'CBM60',\n",
       " 'CBM61',\n",
       " 'CBM62',\n",
       " 'CBM63',\n",
       " 'CBM64',\n",
       " 'CBM65',\n",
       " 'CBM66',\n",
       " 'CBM67',\n",
       " 'CBM68',\n",
       " 'CBM69',\n",
       " 'CBM7',\n",
       " 'CBM70',\n",
       " 'CBM71',\n",
       " 'CBM72',\n",
       " 'CBM73',\n",
       " 'CBM74',\n",
       " 'CBM75',\n",
       " 'CBM76',\n",
       " 'CBM77',\n",
       " 'CBM78',\n",
       " 'CBM79',\n",
       " 'CBM8',\n",
       " 'CBM80',\n",
       " 'CBM81',\n",
       " 'CBM82',\n",
       " 'CBM83',\n",
       " 'CBM84',\n",
       " 'CBM87',\n",
       " 'CBM88',\n",
       " 'CBM9',\n",
       " 'CBM90'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done = set()\n",
    "is_header = False\n",
    "\n",
    "for line in open(\"./raw_data/cazy_gpt3_extract.tsv\", 'r'):\n",
    "    if is_header == False:\n",
    "        is_header = True\n",
    "    else:\n",
    "        done.add(line.split(\"\\t\")[0])\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./raw_data/cazy_activity.tsv\"\n",
    "\n",
    "\n",
    "with open(input_file, 'r', newline=\"\", encoding='utf-8') as infile:\n",
    "\n",
    "    for line in infile:\n",
    "        fields = line.split(\"\\t\")\n",
    "        cazy = fields[0]\n",
    "        raw_text = fields[1]\n",
    "\n",
    "        #if cazy == \"CBM80\":\n",
    "        if cazy.startswith(\"CBM\") and len(raw_text.strip()) > 0 and cazy not in done:\n",
    "            #print (cazy, raw_text)\n",
    "            sentences = (cross_coref.resolve_pronoun(raw_text))\n",
    "\n",
    "            #print (sentences)\n",
    "\n",
    "            #print (f'\"{sent.text.strip()}\"')\n",
    "            res = gpt3.extract_relation(\"gpt3_training.txt\", \"#\" + sentences.strip() + \"\\n\").split(\"\\n\")\n",
    "            #print(\"res:\", cazy, raw_text, res)\n",
    "\n",
    "            for r in res:\n",
    "                results = r.split(\"|\")\n",
    "                #print (results)\n",
    "                content = \"\"\n",
    "                if len(results) == 2 and results[0] != \"COEXISTS\" and results[0] != \"RELATES\":\n",
    "                    #print (\"hello\")\n",
    "                    #print (f\"{doi}|{is_primary}|{results[0]}|{results[1]}|{results[2]}\")\n",
    "                    #print (\"results[1]\", results[1])\n",
    "                    disam = entity_linkage.name_disambiguation(results[1])\n",
    "                    if disam != \"\":\n",
    "                        results[1] = disam\n",
    "\n",
    "                    content = f\"{cazy}\\t{sentences.strip()}\\t{cazy}|\" + \"|\".join(results) + \"\\n\"\n",
    "                else:\n",
    "                    content = f\"{cazy}\\t{sentences.strip()}\\t{cazy}|\" + \"|\".join(results) + \"\\n\"\n",
    "                \n",
    "                nonsensical_relates = False\n",
    "                if results[0] == \"RELATES\":\n",
    "                    if results[1] == cazy:\n",
    "                        nonsensical_relates = True\n",
    "                    if results[1] not in sentences:\n",
    "                        nonsensical_relates = True\n",
    "\n",
    "                if nonsensical_relates == False:\n",
    "                    activity_output = open(\"./raw_data/cazy_gpt3_extract.tsv\", 'a')\n",
    "                    activity_output.write(content)\n",
    "                    activity_output.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_header = False\n",
    "for line in open(\"./raw_data/cazy_gpt3_extract.tsv\", 'r'):\n",
    "    if is_header == False:\n",
    "        is_header = True\n",
    "    else:\n",
    "        relations = line.strip().split(\"\\t\")[2]\n",
    "\n",
    "        fields = relations.split(\"|\")\n",
    "        #print (fields)\n",
    "        subject = fields[0]\n",
    "        verb = fields[1]\n",
    "        object = fields[2]\n",
    "\n",
    "        activity_output = open(\"./raw_data/cazy_subfamily_relation.tsv\", 'a')\n",
    "        activity_output.write(f'{subject}\\t{object}\\t{verb}\\n')\n",
    "        activity_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#input_file = sys.argv[1]\n",
    "\n",
    "input_file = \"./raw_data/cazy_subfamily_relation.tsv\"\n",
    "\n",
    "df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "df[\"doi\"] = \"CAZy\"\n",
    "\n",
    "df[\"primary\"] = 1\n",
    "\n",
    "subfiles = df.action.unique()\n",
    "\n",
    "\n",
    "    #print (df[df.action == s])\n",
    "    \n",
    "    #newfile = os.path.join(output_folder, s + \".tsv\")\n",
    "\n",
    "df.loc[df.action == \"BINDS\", \"to\"] = df[df.action == \"BINDS\"][\"to\"].str.lower()\n",
    "\n",
    "df.to_csv(\"./raw_data/cazy_subfamily_relation_lower.tsv\", sep=\"\\t\", index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha-1,3-glucan',\n",
       " 'alpha-glucans',\n",
       " 'amylopectin',\n",
       " 'amylose',\n",
       " 'arabinofuranose',\n",
       " 'arabinogalactan',\n",
       " 'beta-1,3-1,4-glucan',\n",
       " 'beta-1,3-1,4-mixed linked glucans',\n",
       " 'beta-1,3-glucan',\n",
       " 'beta-1,4-galactan',\n",
       " 'beta-1,4-glucan',\n",
       " 'beta-1,4-glucans',\n",
       " 'beta-1,6-glucan',\n",
       " 'beta-galactan',\n",
       " 'beta-glucans',\n",
       " 'cellooligosaccharides',\n",
       " 'cellulose',\n",
       " 'chitin',\n",
       " 'cyclodextrins',\n",
       " 'fructans',\n",
       " 'fucose',\n",
       " 'galactomannan',\n",
       " 'galactosaminogalactan',\n",
       " 'galactose',\n",
       " 'glucomannan',\n",
       " 'glycogen',\n",
       " 'hyaluronic acid',\n",
       " 'inulin',\n",
       " 'l-rhamnose',\n",
       " 'lactose',\n",
       " 'lipopolysaccharides',\n",
       " 'lipoteichoic acid',\n",
       " 'maltoheptaose',\n",
       " 'maltotetraose',\n",
       " 'maltotriose',\n",
       " 'mannans',\n",
       " 'mannose',\n",
       " 'n-acetyl-lactosamine',\n",
       " 'n-acetylgalactosamine',\n",
       " 'non-crystalline cellulose',\n",
       " 'pectins',\n",
       " 'peptidoglycan',\n",
       " 'polygalacturonic acid',\n",
       " 'pullulan',\n",
       " 'starch',\n",
       " 'ulvan',\n",
       " 'xanthan',\n",
       " 'xylan',\n",
       " 'xylans',\n",
       " 'xyloglucan',\n",
       " 'xylooligosaccharides'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#input_file = sys.argv[1]\n",
    "\n",
    "input_file = \"./data_for_neo4j_bacteroidetes/BINDS.tsv\"\n",
    "\n",
    "df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "sugar = df.to.unique()\n",
    "sugar = set(list(sugar))\n",
    "sugar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta-glucans',\n",
       " 'cellulose',\n",
       " 'fucoidan ',\n",
       " 'glucomannan',\n",
       " 'starch',\n",
       " 'xyloglucan'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "#input_file = sys.argv[1]\n",
    "\n",
    "input_file = \"./data_for_neo4j_bacteroidetes/cazy_literature_extract.tsv\"\n",
    "\n",
    "df = pd.read_csv(input_file, sep='\\t')\n",
    "\n",
    "sugar_1 = df.substrate.unique()\n",
    "sugar_1 = set(list(sugar_1))\n",
    "sugar_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = \"substrate\\n\" + \"\\n\".join(list(sugar.union(sugar_1)))\n",
    "\n",
    "sugar_output = open(\"./data_for_neo4j_bacteroidetes/sugar.tsv\", 'a')\n",
    "sugar_output.write(content)\n",
    "sugar_output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a5a42fb8fac18d5d996f62d59b57d895ef05d83ddcd056098bb0239e44336ef0"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
